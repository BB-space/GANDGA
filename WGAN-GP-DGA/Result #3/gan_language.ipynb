{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import language_helpers\n",
    "import tflib as lib\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.conv1d\n",
    "import tflib.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download Google Billion Word at http://www.statmt.org/lm-benchmark/ and\n",
    "# fill in the path to the extracted files here!\n",
    "DATA_DIR = '../Dataset/AlexaTop1M_NoSeparate'\n",
    "if len(DATA_DIR) == 0:\n",
    "    raise Exception(\"Please specify path to data directory in gan_language.py!\")\n",
    "\n",
    "BATCH_SIZE = 64 # Batch size\n",
    "# How many iterations to train for, min value is 1000, Please increase the number of iteration in 1000 units\n",
    "ITERS = 100000 \n",
    "SEQ_LEN = 32 # Sequence length in characters\n",
    "DIM = 512 # Model dimensionality. This is fairly slow and overfits, even on\n",
    "          # Billion Word. Consider decreasing for smaller datasets.\n",
    "CRITIC_ITERS = 10 # How many critic iterations per generator iteration. We\n",
    "                  # use 10 for the results in the paper, but 5 should work fine\n",
    "                  # as well.\n",
    "LAMBDA = 10 # Gradient penalty lambda hyperparameter.\n",
    "MAX_N_EXAMPLES = 200000 # Max number of data examples to load. If data loading\n",
    "                          # is too slow or takes too much RAM, you can decrease\n",
    "                          # this (at the expense of having less training data). default value is 10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase local vars:\n",
      "\tBATCH_SIZE: 64\n",
      "\tCRITIC_ITERS: 10\n",
      "\tDATA_DIR: ../Dataset/AlexaTop1M_NoSeparate\n",
      "\tDIM: 512\n",
      "\tITERS: 100000\n",
      "\tLAMBDA: 10\n",
      "\tMAX_N_EXAMPLES: 200000\n",
      "\tSEQ_LEN: 32\n",
      "loading dataset...\n",
      "('e', 'd', 'i', 't', 'o', 'r', '.', 'w', 'i', 'x', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('n', 'h', 'i', 's', '.', 'o', 'r', '.', 'k', 'r', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('n', 'i', 'n', 'e', 'r', 'e', 'w', 'a', 'r', 'd', 's', '.', 'c', 'o', 'm', '.', 'a', 'u', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('p', 'a', 'g', 'e', 'u', 'p', 'p', 'e', 'o', 'p', 'l', 'e', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'y', 'b', 'e', 'r', 'a', 'g', 'e', 'n', 't', '.', 'c', 'o', '.', 'j', 'p', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('a', 'n', 'i', 'm', 'e', 'h', 'd', '4', '7', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('a', 'q', 'u', 'i', 'p', 'o', 'r', 'n', 'o', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'a', 'b', 'i', 'o', 'n', 'l', 'i', 'n', 'e', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'o', 'u', 'n', 't', 'a', 'i', 'n', 'c', 'l', 'a', 's', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'e', 'g', 'a', 'o', 'p', 't', '2', '4', '.', 'r', 'u', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('h', 's', 'a', '.', 'g', 'o', 'v', '.', 's', 'g', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('o', 'n', 'e', 's', 'i', 'm', 'c', 'a', 'r', 'd', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('g', 'o', '-', 'e', 't', 'c', '.', 'j', 'p', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('e', 'l', 'f', 'a', 'g', 'r', '.', 'o', 'r', 'g', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'y', 'b', 'e', 'r', 'm', 'a', 'd', 'e', 'i', 'r', 'a', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('t', 'h', 'e', 'y', 'n', 'c', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'o', 'e', '.', 'g', 'o', '.', 'k', 'r', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('t', 'r', 'a', 'd', 'e', 'r', 'a', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('t', 'i', 'n', 'g', 'y', 'u', 'n', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('q', 'u', 'a', 'n', 't', 'i', 'c', 'a', 'l', 'a', 'b', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('d', 'e', 's', 'a', 'f', 'i', 'o', 'n', 'o', 't', 'a', 'm', 'a', 'x', 'i', 'm', 'a', '.', 'c', 'o', 'm', '.', 'b', 'r', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'i', 'r', 'a', 'm', 'a', 'r', 'c', 'i', 'n', 'e', 'm', 'a', 's', '.', 'c', 'o', 'm', '.', 't', 'w', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('u', 'r', 'i', 'c', 'o', 'm', '-', 'n', 'e', 't', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('b', 'e', 's', 'o', 'c', 'c', 'e', 'r', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('v', 'e', 'g', 'a', '-', 'i', 'n', 't', '.', 'r', 'u', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('t', 'a', 'm', 'i', 'l', 'm', 'i', 'r', 'r', 'o', 'r', '.', 'l', 'k', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('a', 's', 's', 'e', 'm', 'b', 'l', 'e', 'y', 'o', 'u', 'r', 'p', 'c', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('0', '5', '9', '0', '.', 'p', 'i', 'c', 's', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('f', 'r', 'e', 's', 'h', 's', 't', 'e', 'p', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('r', 'e', '.', 'v', 'u', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('b', 'u', 'y', 'b', 'a', 'c', 'k', 'w', 'o', 'r', 'l', 'd', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('3', '6', '0', 'i', 'c', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('i', 'a', 'm', 'u', 's', 'i', 'n', 'g', 'm', 'a', 'c', 'a', 'i', 'r', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'i', 's', 's', 'm', 'o', 's', 's', '.', 'c', 'o', '.', 'z', 'a', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('n', 'a', 'b', 'i', 'r', 'a', 'e', 'm', '.', 'r', 'u', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('w', 'i', 'n', 'd', 's', 'o', 'r', 's', 't', 'o', 'r', 'e', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'u', 'd', 'r', 'f', '.', 'r', 'u', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 't', 'e', 'l', 'l', 'a', 'w', 'o', 'r', 't', 'h', '.', 'c', 'o', '.', 'j', 'p', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('a', 'n', 'd', 'y', 'a', '.', 'i', 'r', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('o', 's', 'c', 'a', 's', 'i', 'e', 'r', 'r', 'a', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('e', 'v', 'e', 'n', 't', 'm', 'a', 'n', 'a', 'g', 'e', 'r', 'b', 'l', 'o', 'g', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'h', 'a', 'n', 'n', 'e', 'l', 'g', 'r', 'a', 'b', 'b', 'e', 'r', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('r', 'e', 's', 'e', 'l', 'l', 'e', 'r', 'c', 'l', 'u', 'b', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('x', 'n', '-', '-', 'l', 'g', 'b', 'b', 'z', '3', 'e', '9', 'a', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('p', 'l', 'a', 't', 'r', 'o', 'n', '.', 'r', 'u', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('k', 'i', 'n', 'g', 's', 'o', 'f', 't', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('g', 'u', 'a', 'r', 'd', 'a', 'c', 'h', 'e', 'v', 'i', 'd', 'e', 'o', '.', 'i', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'b', 'e', 'r', 'b', 'a', 'n', 'k', 'o', 'n', 'l', 'i', 'n', 'e', '.', 'r', 'u', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('u', 'n', 'l', 'e', 'a', 's', 'h', 'e', 'd', 's', 'o', 'f', 't', 'w', 'a', 'r', 'e', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('b', 'o', 'l', 'l', 'y', 'b', 'r', 'e', 'a', 'k', '.', 'i', 'n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('d', 'e', 's', 'i', '-', 't', 'e', 'e', 'n', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('k', 'i', 'c', 'k', 'a', 's', 's', 't', 'o', 'r', 'r', 'e', 'n', 't', 's', '.', 't', 'o', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'd', 's', 'h', 'e', 'r', 'i', 'f', 'f', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('q', 'i', 'y', 'a', 'd', 'a', '.', 'm', 'e', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('p', 'o', 'w', 'e', 'r', '-', 'h', 'i', 'k', 'a', 'k', 'u', '.', 'i', 'n', 'f', 'o', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('l', 'a', 't', 'i', 'n', 'c', 'h', 'a', 't', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('a', 'u', 't', 'o', 'e', 'u', 'r', 'o', 'p', 'e', '.', 'e', 'u', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('b', 'u', 'z', 'z', 'c', 'i', 'a', 'o', '.', 'l', 'i', 'n', 'k', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('j', 'a', 'b', 'a', 'r', 'p', 'r', 'o', 'v', '.', 'g', 'o', '.', 'i', 'd', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('p', 'a', 'i', 's', 'd', 'e', 'l', 'o', 's', 'j', 'u', 'e', 'g', 'o', 's', '.', 'c', 'o', 'm', '.', 'm', 'x', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('i', 't', 'o', 'r', 'r', 'e', 'n', 't', 's', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'w', 't', 'o', 'r', 'r', 'e', 'n', 't', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'i', 'n', 'd', 'b', 'u', 'z', 'z', '.', 'o', 'r', 'g', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('j', 'q', 'w', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('a', 'r', 't', 'i', 's', 'a', 'n', 's', 's', 'q', 'u', 'a', 'r', 'e', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'l', 'a', 's', 's', 'm', 'a', 'r', 'k', 'e', 'r', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('f', 'u', 'l', 'l', 'v', 'e', 'r', 's', 'o', 'f', 't', 'w', 'a', 'r', 'e', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('f', 'r', 'o', 'z', 'e', 'n', 'g', 'a', 'm', 'e', 's', '.', 'o', 'r', 'g', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'o', 'r', 'p', 'o', 'r', 'a', 't', 'e', 'h', 'o', 'u', 'r', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('b', 'o', 'u', 'r', 's', 'e', 'p', 'r', 'e', 's', 's', '.', 'i', 'r', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('f', 'u', 't', 'b', 'o', 'l', 't', 'o', 't', 'a', 'l', '.', 'c', 'o', 'm', '.', 'm', 'x', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('f', 'f', 's', 'u', 's', 'u', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('b', 'r', 'a', 's', 'i', 'l', 'b', 'a', 'n', 'd', 'a', 'l', 'a', 'r', 'g', 'a', '.', 'c', 'o', 'm', '.', 'b', 'r', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('r', 'o', 'm', 'a', 'n', 'i', 'a', 'l', 'i', 'b', 'e', 'r', 'a', '.', 'r', 'o', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('g', 'e', 'n', 'e', 'r', 'a', 'l', 'm', 'o', 'b', 'i', 'l', 'e', '.', 'c', 'o', 'm', '.', 't', 'r', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('t', 'i', '.', 't', 'o', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('o', 'n', 'l', 'i', 'n', 'e', 'a', 't', 'h', 'e', 'n', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'h', 'e', 'n', 'g', '8', '0', '0', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('n', 'a', 's', 'h', 'a', 'u', 'c', 'h', 'e', 'b', 'a', '.', 'r', 'u', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('n', 'i', 'm', 'b', 'l', 'e', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('p', 'r', 'o', 'c', 'a', 'b', 'l', 'e', '.', 'j', 'p', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('d', 'o', 'c', 'p', 'l', 'a', 'y', 'e', 'r', '.', 'p', 'l', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('y', 'i', 'm', 'u', 'h', 'e', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('e', 'n', 't', 'e', 'r', '.', 'a', 'z', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('v', 'i', 'r', 'a', 'l', 's', 'p', 'r', 'i', 'n', 't', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('a', 'c', 'l', 'i', '.', 'i', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('e', 'v', 'e', 'n', 't', 'i', 'm', '.', 'r', 'o', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('p', 'l', 'a', 'c', 'e', 't', 'o', 'p', 'a', 'y', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('v', 'o', 'd', 'i', 'e', 'n', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('e', 'v', 'e', 'n', 'f', 'l', 'o', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('t', 'a', 'g', 'e', 's', 'g', 'e', 'l', 'd', 'v', 'e', 'r', 'g', 'l', 'e', 'i', 'c', 'h', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'a', 's', 't', 't', 'o', '.', 'm', 'e', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('n', 'i', 'c', 'h', 'e', 'g', 'a', 'l', 'z', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('k', 'a', 'm', 'p', 'u', 's', 'b', 'e', 't', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('0', '6', '4', '2', '.', 'p', 'i', 'c', 's', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('x', 'z', '7', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('w', 'a', 't', 'c', 'h', '3', '2', 'm', 'o', 'v', 'i', 'e', 's', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('g', 'd', 'o', 'c', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('i', 'c', 'e', 'l', 'e', 'a', 'd', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('b', 'i', 'c', 'c', 'a', 'm', 'e', 'r', 'a', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "loaded 200000 lines in dataset\n"
     ]
    }
   ],
   "source": [
    "lib.print_model_settings(locals().copy())\n",
    "\n",
    "lines, charmap, inv_charmap = language_helpers.load_dataset(\n",
    "    max_length=SEQ_LEN,\n",
    "    max_n_examples=MAX_N_EXAMPLES,\n",
    "    data_dir=DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    return tf.reshape(\n",
    "        tf.nn.softmax(\n",
    "            tf.reshape(logits, [-1, len(charmap)])\n",
    "        ),\n",
    "        tf.shape(logits)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_noise(shape):\n",
    "    return tf.random_normal(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ResBlock(name, inputs):\n",
    "    output = inputs\n",
    "    output = tf.nn.relu(output)\n",
    "    output = lib.ops.conv1d.Conv1D(name+'.1', DIM, DIM, 5, output)\n",
    "    output = tf.nn.relu(output)\n",
    "    output = lib.ops.conv1d.Conv1D(name+'.2', DIM, DIM, 5, output)\n",
    "    return inputs + (0.3*output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Generator(n_samples, prev_outputs=None):\n",
    "    output = make_noise(shape=[n_samples, 128])\n",
    "    output = lib.ops.linear.Linear('Generator.Input', 128, SEQ_LEN*DIM, output)\n",
    "    output = tf.reshape(output, [-1, DIM, SEQ_LEN])\n",
    "    output = ResBlock('Generator.1', output)\n",
    "    output = ResBlock('Generator.2', output)\n",
    "    output = ResBlock('Generator.3', output)\n",
    "    output = ResBlock('Generator.4', output)\n",
    "    output = ResBlock('Generator.5', output)\n",
    "    output = lib.ops.conv1d.Conv1D('Generator.Output', DIM, len(charmap), 1, output)\n",
    "    output = tf.transpose(output, [0, 2, 1])\n",
    "    output = softmax(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Discriminator(inputs):\n",
    "    output = tf.transpose(inputs, [0,2,1])\n",
    "    output = lib.ops.conv1d.Conv1D('Discriminator.Input', len(charmap), DIM, 1, output)\n",
    "    output = ResBlock('Discriminator.1', output)\n",
    "    output = ResBlock('Discriminator.2', output)\n",
    "    output = ResBlock('Discriminator.3', output)\n",
    "    output = ResBlock('Discriminator.4', output)\n",
    "    output = ResBlock('Discriminator.5', output)\n",
    "    output = tf.reshape(output, [-1, SEQ_LEN*DIM])\n",
    "    output = lib.ops.linear.Linear('Discriminator.Output', SEQ_LEN*DIM, 1, output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_inputs_discrete = tf.placeholder(tf.int32, shape=[BATCH_SIZE, SEQ_LEN])\n",
    "real_inputs = tf.one_hot(real_inputs_discrete, len(charmap))\n",
    "fake_inputs = Generator(BATCH_SIZE)\n",
    "fake_inputs_discrete = tf.argmax(fake_inputs, fake_inputs.get_shape().ndims-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disc_real = Discriminator(real_inputs) \n",
    "disc_fake = Discriminator(fake_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "gen_cost = -tf.reduce_mean(disc_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WGAN lipschitz-penalty\n",
    "alpha = tf.random_uniform(\n",
    "    shape=[BATCH_SIZE,1,1], \n",
    "    minval=0.,\n",
    "    maxval=1.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "differences = fake_inputs - real_inputs\n",
    "interpolates = real_inputs + (alpha*differences)\n",
    "gradients = tf.gradients(Discriminator(interpolates), [interpolates])[0]\n",
    "slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1,2]))\n",
    "gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "disc_cost += LAMBDA*gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_params = lib.params_with_name('Generator')\n",
    "disc_params = lib.params_with_name('Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_train_op = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9).minimize(gen_cost, var_list=gen_params)\n",
    "disc_train_op = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9).minimize(disc_cost, var_list=disc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset iterator\n",
    "def inf_train_gen():\n",
    "    while True:\n",
    "        np.random.shuffle(lines)\n",
    "        for i in range(0, len(lines)-BATCH_SIZE+1, BATCH_SIZE):\n",
    "            yield np.array(\n",
    "                [[charmap[c] for c in l] for l in lines[i:i+BATCH_SIZE]], \n",
    "                dtype='int32'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set JSD for n=1: 0.00034957248523905145\n",
      "validation set JSD for n=2: 0.01140526306778135\n",
      "validation set JSD for n=3: 0.08067943870716257\n",
      "validation set JSD for n=4: 0.18350008884953134\n"
     ]
    }
   ],
   "source": [
    "# During training we monitor JS divergence between the true & generated ngram\n",
    "# distributions for n=1,2,3,4. To get an idea of the optimal values, we\n",
    "# evaluate these statistics on a held-out set first.\n",
    "\n",
    "true_char_ngram_lms = [language_helpers.NgramLanguageModel(i+1, lines[10*BATCH_SIZE:], tokenize=False) for i in range(4)]\n",
    "validation_char_ngram_lms = [language_helpers.NgramLanguageModel(i+1, lines[:10*BATCH_SIZE], tokenize=False) for i in range(4)]\n",
    "for i in range(4):\n",
    "    print ( \"validation set JSD for n={}: {}\".format(i+1, true_char_ngram_lms[i].js_with(validation_char_ngram_lms[i])) )\n",
    "true_char_ngram_lms = [language_helpers.NgramLanguageModel(i+1, lines, tokenize=False) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Start]\n",
      "    1% Done! [Iteration]:       1000 [1000x iterations time  ]:    1947.39 secs [SUM]:    1947.39 secs\n",
      "iter 999\tjs1\t0.019558178736994995\tjs4\t0.2930032372242495\tjs2\t0.08416957214197109\tjs3\t0.19536828871808945\ttrain disc cost\t-2.601283073425293\ttime\t1.947542394399643\n",
      "    2% Done! [Iteration]:       2000 [1000x iterations time  ]:    1970.18 secs [SUM]:    3917.57 secs\n",
      "iter 1999\tjs1\t0.011232976187447\tjs4\t0.2612906812249499\tjs2\t0.05197296562431203\tjs3\t0.15627721198682099\ttrain disc cost\t-2.2695581912994385\ttime\t1.9687734484672545\n",
      "    3% Done! [Iteration]:       3000 [1000x iterations time  ]:    1970.86 secs [SUM]:    5888.43 secs\n",
      "iter 2999\tjs1\t0.009408615340621932\tjs4\t0.26166002241781966\tjs2\t0.04324926602565659\tjs3\t0.15009278217595984\ttrain disc cost\t-2.212721347808838\ttime\t1.9692760140895844\n",
      "    4% Done! [Iteration]:       4000 [1000x iterations time  ]:    1970.46 secs [SUM]:    7858.90 secs\n",
      "iter 3999\tjs1\t0.007560784330645938\tjs4\t0.24793178985590789\tjs2\t0.037929752295340034\tjs3\t0.1355801112996165\ttrain disc cost\t-2.235489845275879\ttime\t1.9690124094486237\n",
      "    5% Done! [Iteration]:       5000 [1000x iterations time  ]:    1969.38 secs [SUM]:    9828.27 secs\n",
      "iter 4999\tjs1\t0.009322758310296067\tjs4\t0.2789849528678086\tjs2\t0.04282676747933983\tjs3\t0.14809577034195642\ttrain disc cost\t-2.262350559234619\ttime\t1.967911666870117\n",
      "    6% Done! [Iteration]:       6000 [1000x iterations time  ]:    1963.45 secs [SUM]:   11791.73 secs\n",
      "iter 5999\tjs1\t0.004657012103187499\tjs4\t0.2573246427624465\tjs2\t0.03356611892966509\tjs3\t0.13411282366694774\ttrain disc cost\t-2.2657063007354736\ttime\t1.9619825408458709\n",
      "    7% Done! [Iteration]:       7000 [1000x iterations time  ]:    1963.26 secs [SUM]:   13754.99 secs\n",
      "iter 6999\tjs1\t0.00572131922776672\tjs4\t0.241441694756988\tjs2\t0.031237690798321126\tjs3\t0.12379710601339458\ttrain disc cost\t-2.2658867835998535\ttime\t1.9616298003196717\n",
      "    8% Done! [Iteration]:       8000 [1000x iterations time  ]:    1962.23 secs [SUM]:   15717.22 secs\n",
      "iter 7999\tjs1\t0.006869983888992076\tjs4\t0.24899453849114692\tjs2\t0.0368687184088631\tjs3\t0.1344875655053086\ttrain disc cost\t-2.2711031436920166\ttime\t1.9607362213134765\n",
      "    9% Done! [Iteration]:       9000 [1000x iterations time  ]:    1966.42 secs [SUM]:   17683.64 secs\n",
      "iter 8999\tjs1\t0.004139449850904438\tjs4\t0.2388612065620332\tjs2\t0.029265096346050106\tjs3\t0.12610464554028872\ttrain disc cost\t-2.275179862976074\ttime\t1.9649121959209441\n",
      "   10% Done! [Iteration]:      10000 [1000x iterations time  ]:    1915.64 secs [SUM]:   19599.28 secs\n",
      "iter 9999\tjs1\t0.0032901875807367868\tjs4\t0.23660118827346516\tjs2\t0.02472100344189945\tjs3\t0.11795522091971537\ttrain disc cost\t-2.2917401790618896\ttime\t1.9139715189933777\n",
      "   11% Done! [Iteration]:      11000 [1000x iterations time  ]:    1891.06 secs [SUM]:   21490.35 secs\n",
      "iter 10999\tjs1\t0.00510739968803315\tjs4\t0.2587625120489767\tjs2\t0.032403773454310565\tjs3\t0.13292987869975367\ttrain disc cost\t-2.319983959197998\ttime\t1.889505876302719\n",
      "   12% Done! [Iteration]:      12000 [1000x iterations time  ]:    1894.57 secs [SUM]:   23384.92 secs\n",
      "iter 11999\tjs1\t0.006956383512322085\tjs4\t0.247129208894844\tjs2\t0.0371363561206271\tjs3\t0.13281888194507366\ttrain disc cost\t-2.3379032611846924\ttime\t1.893077714204788\n",
      "   13% Done! [Iteration]:      13000 [1000x iterations time  ]:    1893.29 secs [SUM]:   25278.21 secs\n",
      "iter 12999\tjs1\t0.0035972194094181747\tjs4\t0.23943877509605016\tjs2\t0.02685104434994857\tjs3\t0.12182140464055707\ttrain disc cost\t-2.3448686599731445\ttime\t1.8917756464481355\n",
      "   14% Done! [Iteration]:      14000 [1000x iterations time  ]:    1905.71 secs [SUM]:   27183.92 secs\n",
      "iter 13999\tjs1\t0.005568013117361199\tjs4\t0.22998172529015654\tjs2\t0.03113560554176543\tjs3\t0.12272532148182544\ttrain disc cost\t-2.365710973739624\ttime\t1.9040294919013978\n",
      "   15% Done! [Iteration]:      15000 [1000x iterations time  ]:    1899.92 secs [SUM]:   29083.84 secs\n",
      "iter 14999\tjs1\t0.0050609341231871025\tjs4\t0.23355212353544738\tjs2\t0.029980393113126058\tjs3\t0.12075121065918604\ttrain disc cost\t-2.425480842590332\ttime\t1.8982495079040527\n",
      "   16% Done! [Iteration]:      16000 [1000x iterations time  ]:    1891.91 secs [SUM]:   30975.74 secs\n",
      "iter 15999\tjs1\t0.008979062188415543\tjs4\t0.23152137438447304\tjs2\t0.037057687249877215\tjs3\t0.127857103367114\ttrain disc cost\t-2.405609607696533\ttime\t1.8903123846054077\n",
      "   17% Done! [Iteration]:      17000 [1000x iterations time  ]:    1890.64 secs [SUM]:   32866.38 secs\n",
      "iter 16999\tjs1\t0.005816493904805033\tjs4\t0.26257890041027326\tjs2\t0.03446950435944946\tjs3\t0.1386151742824593\ttrain disc cost\t-2.5022740364074707\ttime\t1.8890431969165802\n",
      "   18% Done! [Iteration]:      18000 [1000x iterations time  ]:    1886.27 secs [SUM]:   34752.65 secs\n",
      "iter 17999\tjs1\t0.005296675942668139\tjs4\t0.22998537837005537\tjs2\t0.029886239855110505\tjs3\t0.12145508873588913\ttrain disc cost\t-2.580352544784546\ttime\t1.884486971139908\n",
      "   19% Done! [Iteration]:      19000 [1000x iterations time  ]:    1893.28 secs [SUM]:   36645.93 secs\n",
      "iter 18999\tjs1\t0.00434057000109343\tjs4\t0.23487783604025406\tjs2\t0.02879530197752638\tjs3\t0.12258191487385002\ttrain disc cost\t-2.6797304153442383\ttime\t1.8916876175403594\n",
      "   20% Done! [Iteration]:      20000 [1000x iterations time  ]:    1891.12 secs [SUM]:   38537.06 secs\n",
      "iter 19999\tjs1\t0.0058072732389232145\tjs4\t0.2371005879857555\tjs2\t0.03309977597255061\tjs3\t0.1248425942335074\ttrain disc cost\t-2.6723153591156006\ttime\t1.8894828016757965\n",
      "   21% Done! [Iteration]:      21000 [1000x iterations time  ]:    1892.39 secs [SUM]:   40429.44 secs\n",
      "iter 20999\tjs1\t0.007405086000327423\tjs4\t0.2568597340895642\tjs2\t0.04058116299600517\tjs3\t0.14016612310062135\ttrain disc cost\t-2.797274589538574\ttime\t1.890462512254715\n",
      "   22% Done! [Iteration]:      22000 [1000x iterations time  ]:    1881.80 secs [SUM]:   42311.25 secs\n",
      "iter 21999\tjs1\t0.010341006324483154\tjs4\t0.2585070401186583\tjs2\t0.0505892625011762\tjs3\t0.1541157365934413\ttrain disc cost\t-2.933555841445923\ttime\t1.8801607525348663\n",
      "   23% Done! [Iteration]:      23000 [1000x iterations time  ]:    1885.41 secs [SUM]:   44196.66 secs\n",
      "iter 22999\tjs1\t0.01120941582669794\tjs4\t0.24334819665354324\tjs2\t0.04731973444189681\tjs3\t0.14376234091505932\ttrain disc cost\t-2.9459242820739746\ttime\t1.8837738590240478\n",
      "   24% Done! [Iteration]:      24000 [1000x iterations time  ]:    1884.74 secs [SUM]:   46081.40 secs\n",
      "iter 23999\tjs1\t0.011047732670574174\tjs4\t0.2913837226374937\tjs2\t0.058542882257265866\tjs3\t0.1693381452644295\ttrain disc cost\t-2.9993746280670166\ttime\t1.8830536670684814\n",
      "   25% Done! [Iteration]:      25000 [1000x iterations time  ]:    1872.92 secs [SUM]:   47954.31 secs\n",
      "iter 24999\tjs1\t0.007014022856666894\tjs4\t0.27276144866777274\tjs2\t0.04346654261865648\tjs3\t0.15051041511066024\ttrain disc cost\t-3.0841903686523438\ttime\t1.8711105546951294\n",
      "   26% Done! [Iteration]:      26000 [1000x iterations time  ]:    1872.70 secs [SUM]:   49827.01 secs\n",
      "iter 25999\tjs1\t0.006266754854418931\tjs4\t0.2490753864629031\tjs2\t0.03633188202052018\tjs3\t0.13432607760117704\ttrain disc cost\t-3.178149938583374\ttime\t1.8710548732280732\n",
      "   27% Done! [Iteration]:      27000 [1000x iterations time  ]:    1885.34 secs [SUM]:   51712.35 secs\n",
      "iter 26999\tjs1\t0.01009499176484163\tjs4\t0.2729248577938458\tjs2\t0.05011368391066807\tjs3\t0.15692360502195166\ttrain disc cost\t-3.194052219390869\ttime\t1.883713044166565\n",
      "   28% Done! [Iteration]:      28000 [1000x iterations time  ]:    1882.00 secs [SUM]:   53594.35 secs\n",
      "iter 27999\tjs1\t0.01595989272471008\tjs4\t0.2691467121249605\tjs2\t0.061206650583952846\tjs3\t0.16199173775894027\ttrain disc cost\t-3.239339828491211\ttime\t1.8801908371448517\n",
      "   29% Done! [Iteration]:      29000 [1000x iterations time  ]:    1885.27 secs [SUM]:   55479.62 secs\n",
      "iter 28999\tjs1\t0.016289726250806616\tjs4\t0.2437330402413928\tjs2\t0.05907195306405946\tjs3\t0.15497098983522045\ttrain disc cost\t-3.3845293521881104\ttime\t1.8836306371688842\n",
      "   30% Done! [Iteration]:      30000 [1000x iterations time  ]:    1872.87 secs [SUM]:   57352.50 secs\n",
      "iter 29999\tjs1\t0.022910139965413266\tjs4\t0.25701981760772685\tjs2\t0.06843271589496908\tjs3\t0.17079843295008407\ttrain disc cost\t-3.448690891265869\ttime\t1.871204382419586\n",
      "[*****     ] [Iteration]:      30500 [Unit iteration time    ]:       1.88 secs [ETA]:  130832.96 secs\r"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    def generate_samples():\n",
    "        samples = session.run(fake_inputs)\n",
    "        samples = np.argmax(samples, axis=2)\n",
    "        decoded_samples = []\n",
    "        for i in range(len(samples)):\n",
    "            decoded = []\n",
    "            for j in range(len(samples[i])):\n",
    "                decoded.append(inv_charmap[samples[i][j]])\n",
    "            decoded_samples.append(tuple(decoded))\n",
    "        return decoded_samples\n",
    "\n",
    "    gen = inf_train_gen()\n",
    "\n",
    "    sum_time = 0.\n",
    "    line_time = 0. \n",
    "    loading_str = \"*\"\n",
    "    for iteration in range(ITERS):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if (iteration == 0):\n",
    "            now_time = time.clock()\n",
    "            print(\"[Start]\")\n",
    "\n",
    "        # Train generator\n",
    "        if iteration > 0:\n",
    "            _ = session.run(gen_train_op)\n",
    "\n",
    "        # Train critic\n",
    "        for i in range(CRITIC_ITERS):\n",
    "            _data = gen.__next__()\n",
    "            _disc_cost, _ = session.run(\n",
    "                [disc_cost, disc_train_op],\n",
    "                feed_dict={real_inputs_discrete:_data}\n",
    "            )\n",
    "            \n",
    "            #print(\"_disc_cost \"+str(_disc_cost))\n",
    "            #print(\"_ \"+str(_))\n",
    "            #print(\"_data \"+str(_data))\n",
    "            #print(\"gen_cost \"+str(gen_cost))\n",
    "            #print(\"disc_cost\"+str(disc_cost))\n",
    "\n",
    "        # How many iterations to change line \n",
    "        change_line=int(ITERS/1000)\n",
    "        \n",
    "        after_time=time.clock() - now_time\n",
    "        sum_time+=after_time\n",
    "        eta_time = (ITERS-iteration)*(after_time)\n",
    "        \n",
    "        print(\"[{1:10}] [Iteration]: {0:10} [Unit iteration time    ]: {2:10.2f} secs [ETA]: {3:10.2f} secs\".format( (iteration+1), loading_str, after_time, eta_time) , end=\"\\r\")\n",
    "        now_time = time.clock()\n",
    "        if iteration % change_line == (change_line-1):\n",
    "            loading_str += \"*\"\n",
    "            if iteration % (10*change_line) == (10*change_line-1):            \n",
    "                print(\"{5:5.0f}{0:7} [Iteration]: {1:10} [{2:23}]: {3:10.2f} secs [SUM]: {4:10.2f}\".format(\"% Done!\", (iteration+1), (str(10*change_line)+\"x iterations time\"), (sum_time-line_time), sum_time, (100*iteration/ITERS) ) )\n",
    "                loading_str = \"*\"\n",
    "                line_time = sum_time\n",
    "        \n",
    "        lib.plot.plot('time', time.time() - start_time)\n",
    "        lib.plot.plot('train disc cost', _disc_cost)        \n",
    "\n",
    "        if iteration % (10*change_line) == (10*change_line-1):\n",
    "            #print(\"checkpintB\"+str(iteration+1))\n",
    "            samples = []\n",
    "            for i in range(10):\n",
    "                samples.extend(generate_samples())\n",
    "\n",
    "            for i in range(4):\n",
    "                lm = language_helpers.NgramLanguageModel(i+1, samples, tokenize=False)\n",
    "                lib.plot.plot('js{}'.format(i+1), lm.js_with(true_char_ngram_lms[i]))\n",
    "\n",
    "            with open('output_data/samples_{}.txt'.format(str(iteration+1).zfill(7)), 'w',encoding = 'utf8') as f:\n",
    "                for s in samples:\n",
    "                    s = \"\".join(s)\n",
    "                    s = language_helpers.checkDNSFrom(s)\n",
    "                    f.write(str(s) + \"\\n\")\n",
    "\n",
    "        if iteration % (10*change_line) == (10*change_line-1):\n",
    "            #print(iteration)\n",
    "            lib.plot.flush()\n",
    "        \n",
    "        lib.plot.tick()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
